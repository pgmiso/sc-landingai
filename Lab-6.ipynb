{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Lab 6: Building AWS Pipelines with Agentic Document Extraction\n",
    "\n",
    "In this lab, you will build a pipeline that combines automated document processing with a conversational chatbot featuring memory and visual grounding.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Build an event-driven, serverless  pipeline on AWS\n",
    "- Deploy a Lambda function that parses PDFs automatically using LandingAI ADE\n",
    "- Ingest parsed documents into Amazon Bedrock Knowledge Base\n",
    "- Create a Strands Agent with persistent memory and visual grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "background-cell",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In the previous lab, you built a RAG pipeline using local components. This lab migrates to the cloud on AWS:\n",
    "\n",
    "| Lab 5 | Lab 6 | Difference |\n",
    "|-----------------|----------------|----------|\n",
    "| Local files | **Amazon S3** | Scalable storage |\n",
    "| Local scripts | **AWS Lambda** | Serverless compute |\n",
    "| ChromaDB | **Bedrock Knowledge Base** | Managed vector database |\n",
    "| OpenAI | **Amazon Titan** | AWS embedding model |\n",
    "| LangChain | **Strands Agents** | AWS agent framework |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outline-cell",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "**Part 1: Setting Up the Lambda Function**\n",
    "- [Step 1: Environment Setup](#step1)\n",
    "- [Step 2: Initialize AWS Clients](#step2)\n",
    "- [Step 3: Create the Deployment Package](#step3)\n",
    "- [Step 4: Create the IAM Role](#step4)\n",
    "- [Step 5: Deploy the Lambda Function](#step5)\n",
    "- [Step 6: Set Up the S3 Trigger](#step6)\n",
    "\n",
    "**Part 2: Building the Knowledge Base**\n",
    "- [Step 7: Upload Documents for Processing](#step7)\n",
    "- [Step 8: Connect to the Bedrock Knowledge Base](#step8)\n",
    "- [Step 9: Ingest Documents into the Knowledge Base](#step9)\n",
    "\n",
    "**Part 3: Building the Agent**\n",
    "- [Step 10: Create the Search Tool with Visual Grounding](#step10)\n",
    "- [Step 11: Create Memory for the Agent](#step11)\n",
    "- [Step 12: Create the Strands Agent](#step12)\n",
    "- [Step 13: Interactive Chat](#step13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prereq-note",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Prerequisites)</code>:</b> This lab assumes you have an AWS account with an S3 bucket (with input/output folders) and a Bedrock Knowledge Base connected to the output folder. Links for setting up these resources are provided in the <code>README</code> file.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture-header",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "The complete data flow:\n",
    "\n",
    "1. **Upload**: User uploads PDF to S3 `input/` folder\n",
    "2. **Trigger**: S3 automatically triggers Lambda function\n",
    "3. **Parse**: Lambda uses LandingAI ADE to parse PDF into structured markdown\n",
    "4. **Store**: Parsed output (markdown, grounding data, chunks) saved to S3 `output/` folder\n",
    "5. **Index**: Bedrock Knowledge Base indexes documents for semantic search\n",
    "6. **Query**: Users ask questions to the Strands agent with memory\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/architecture_1.png\" width=\"700\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## Installing Required Packages\n",
    "\n",
    "Install the AWS and agent packages:\n",
    "- **boto3**: AWS SDK for Python\n",
    "- **bedrock-agentcore**: Memory management for agents\n",
    "- **strands-agents**: AWS-native agent framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install --quiet boto3 python-dotenv Pillow PyMuPDF bedrock-agentcore strands-agents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "\n",
    "## Step 1: Environment Setup\n",
    "\n",
    "Load environment variables containing AWS credentials and configuration from a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-example",
   "metadata": {},
   "source": [
    "**Example `.env` file:**\n",
    "```bash\n",
    "# AWS Credentials\n",
    "AWS_ACCESS_KEY_ID=your_aws_access_key\n",
    "AWS_SECRET_ACCESS_KEY=your_aws_secret_key\n",
    "AWS_REGION=your_aws_region\n",
    "\n",
    "# S3 Bucket\n",
    "S3_BUCKET=your_bucket_name\n",
    "\n",
    "# Bedrock Configuration\n",
    "BEDROCK_MODEL_ID=your_llm_id\n",
    "BEDROCK_KB_ID=your_bedrock_knowledge_base_id\n",
    "DATA_SOURCE_ID=your_data_source_id\n",
    "\n",
    "# LandingAI ADE API Key\n",
    "VISION_AGENT_API_KEY=your_vision_api_key\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "\n",
    "## Step 2: Initialize AWS Clients\n",
    "\n",
    "The `boto3` library connects to AWS services through **clients**. Each client provides access to a specific service:\n",
    "\n",
    "| Client | Service | Purpose |\n",
    "|--------|---------|--------|\n",
    "| `s3_client` | Amazon S3 | Upload/download files, manage buckets |\n",
    "| `lambda_client` | AWS Lambda | Deploy functions, configure triggers |\n",
    "| `iam` | IAM | Create roles with permissions |\n",
    "| `logs` | CloudWatch | Monitor Lambda execution |\n",
    "| `bedrock_agent_runtime` | Bedrock | Query knowledge bases |\n",
    "| `bedrock_runtime` | Bedrock | Call Claude models directly |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clients-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    region_name=os.getenv(\"AWS_REGION\"),\n",
    ")\n",
    "\n",
    "# Create clients\n",
    "s3_client = session.client(\"s3\")\n",
    "lambda_client = session.client(\"lambda\")\n",
    "iam = session.client(\"iam\")  # Add IAM client for Lambda role management\n",
    "logs = session.client(\"logs\")  # CloudWatch Logs client for monitoring\n",
    "bedrock_agent_runtime = session.client(\"bedrock-agent-runtime\")\n",
    "bedrock_runtime = session.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parts-overview",
   "metadata": {},
   "source": [
    "# Building a Medical Chatbot with Memory\n",
    "\n",
    "The pipeline is built in three parts:\n",
    "\n",
    "### Part 1: Setting Up the Lambda Function (Steps 3-5)\n",
    "Package code, create IAM role, deploy function.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/steps3-5.png\" width=\"700\">\n",
    "</div>\n",
    "\n",
    "### Part 2: Setting Up the Trigger (Step 6)\n",
    "Configure S3 to invoke Lambda on file uploads.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/step6.png\" width=\"200\">\n",
    "</div>\n",
    "\n",
    "### Part 3: Building the Agent (Steps 7-12)\n",
    "Upload documents, ingest into knowledge base, create agent with memory.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/steps7-12.png\" width=\"700\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "### Loading Helper Functions\n",
    "\n",
    "Helper functions in `lambda_helpers.py` handle AWS operations like creating deployment packages, configuring IAM roles, and setting up triggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions\n",
    "import pandas as pd\n",
    "from lambda_helpers import *\n",
    "\n",
    "print(\"Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "\n",
    "## Step 3: Create the Deployment Package\n",
    "\n",
    "### What is a Lambda Deployment Package?\n",
    "\n",
    "AWS Lambda requires your code and dependencies bundled in a **zip file**:\n",
    "\n",
    "```\n",
    "ade_lambda.zip\n",
    "‚îú‚îÄ‚îÄ ade_s3_handler.py          ‚Üê Your code (handler function)\n",
    "‚îú‚îÄ‚îÄ landingai_ade/             ‚Üê LandingAI ADE package\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ typing_extensions/         ‚Üê typing-extensions package\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ boto3/                     ‚Üê AWS SDK (often pre-installed)\n",
    "    ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "The helper function creates this package by:\n",
    "1. Creating a temporary directory\n",
    "2. Installing pip packages into that directory\n",
    "3. Copying your source code files\n",
    "4. Zipping everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "package-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = [\"ade_s3_handler.py\"]\n",
    "requirements = [\"landingai-ade\", \"typing-extensions\"]\n",
    "\n",
    "zip_path = create_deployment_package(\n",
    "    source_files=source_files,\n",
    "    requirements=requirements,\n",
    "    output_zip=\"ade_lambda.zip\",\n",
    "    package_dir=\"ade_package\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handler-explain",
   "metadata": {},
   "source": [
    "###  `ade_s3_handler.py` File\n",
    "\n",
    "This code runs inside Lambda when triggered:\n",
    "\n",
    "1. **Event received**: S3 upload triggers Lambda with file information\n",
    "2. **Validation**: Check it's a PDF, not a folder, and output doesn't exist\n",
    "3. **Download**: PDF downloaded to Lambda's `/tmp` directory\n",
    "4. **Parse**: ADE API parses PDF into markdown and chunks\n",
    "5. **Upload**: Results saved to S3 output folder in three formats:\n",
    "   - **Markdown**: Complete document in readable format\n",
    "   - **Grounding JSON**: All chunks with bounding box coordinates\n",
    "   - **Individual chunks**: One file per chunk for knowledge base indexing\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/flow_ade_handler.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "files-explain",
   "metadata": {},
   "source": [
    "### Understanding the Output Files\n",
    "\n",
    "When a PDF is processed, Lambda produces three types of outputs in the S3 `output/` folder:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/files.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "<a id=\"step4\"></a>\n",
    "\n",
    "\n",
    "## Step 4: Create the IAM Role\n",
    "\n",
    "### What is an IAM Role?\n",
    "\n",
    "Lambda functions run in **isolated containers** with no inherent permissions. An **IAM role** grants the function permission to access specific AWS services.\n",
    "\n",
    "| Permission | Purpose |\n",
    "|------------|--------|\n",
    "| `s3:GetObject` | Read PDFs from input folder |\n",
    "| `s3:PutObject` | Write markdown to output folder |\n",
    "| `s3:HeadObject` | Check if output already exists |\n",
    "| `logs:CreateLogGroup` | Create CloudWatch log group |\n",
    "| `logs:CreateLogStream` | Create log stream per execution |\n",
    "| `logs:PutLogEvents` | Write log entries for debugging |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "role-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn = create_or_update_lambda_role(\n",
    "    iam_client=iam,\n",
    "    role_name=\"lambda-ade-exec-role\",\n",
    "    description=\"Execution role for LandingAI ADE Lambda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-header",
   "metadata": {},
   "source": [
    "<a id=\"step5\"></a>\n",
    "\n",
    "\n",
    "## Step 5: Deploy the Lambda Function\n",
    "\n",
    "Deploy with both required components:\n",
    "- **Deployment package**: Code (zip file)\n",
    "- **IAM role**: Permissions\n",
    "\n",
    "The configuration includes:\n",
    "- **Environment variables**: Configuration accessible at runtime\n",
    "- **Timeout**: 900 seconds (15 minutes) for larger PDFs\n",
    "- **Memory**: 1024 MB RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deploy-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars = {\n",
    "    \"VISION_AGENT_API_KEY\": os.getenv(\"VISION_AGENT_API_KEY\"),\n",
    "    \"ADE_MODEL\": \"dpt-2-latest\",\n",
    "    \"INPUT_FOLDER\": \"input/\",\n",
    "    \"OUTPUT_FOLDER\": \"output/\",\n",
    "    \"S3_BUCKET\": os.getenv(\"S3_BUCKET\"),\n",
    "    \"FORCE_REPROCESS\": \"false\"  # Set to \"true\" to reprocess all files even if outputs exist\n",
    "}\n",
    "\n",
    "response = deploy_lambda_function(\n",
    "    lambda_client=lambda_client,\n",
    "    function_name=\"ade-s3-handler\",\n",
    "    zip_file=\"ade_lambda.zip\",\n",
    "    role_arn=role_arn,\n",
    "    handler=\"ade_s3_handler.ade_handler\",\n",
    "    env_vars=env_vars,\n",
    "    runtime=\"python3.10\",\n",
    "    timeout=900,\n",
    "    memory_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6-header",
   "metadata": {},
   "source": [
    "<a id=\"step6\"></a>\n",
    "\n",
    "\n",
    "## Step 6: Set Up the S3 Trigger\n",
    "\n",
    "The Lambda function is deployed but won't run automatically yet. Configure S3 to **trigger Lambda when files are uploaded**.\n",
    "\n",
    "S3 sends events when objects are created, modified, or deleted. We'll configure it to invoke our function when files are uploaded to the `input/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trigger-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger on all files in input/ folder\n",
    "setup_s3_trigger(\n",
    "    s3_client=s3_client,\n",
    "    lambda_client=lambda_client,\n",
    "    bucket=os.getenv(\"S3_BUCKET\"),\n",
    "    prefix=\"input/\",\n",
    "    function_name=\"ade-s3-handler\",\n",
    "    suffix=None  # Optional: set to \".pdf\" to only trigger on PDF files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7-header",
   "metadata": {},
   "source": [
    "<a id=\"step7\"></a>\n",
    "\n",
    "\n",
    "## Step 7: Upload Documents for Processing\n",
    "\n",
    "Upload medical PDF documents and watch the pipeline in action.\n",
    "\n",
    "When you upload files to `input/`, the event-driven architecture automatically:\n",
    "1. Detects new files\n",
    "2. Triggers Lambda\n",
    "3. Parses with ADE\n",
    "4. Saves outputs to `output/`\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/folders_s3.png\" width=\"750\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload medical documents to S3 input folder\n",
    "local_folder = \"medical/\"\n",
    "\n",
    "# Check if folder exists and upload\n",
    "if os.path.exists(local_folder):\n",
    "    count = upload_folder_to_s3(\n",
    "        s3_client=s3_client,\n",
    "        local_folder=local_folder,\n",
    "        s3_prefix=f\"input/{local_folder}\",\n",
    "        bucket=os.getenv(\"S3_BUCKET\"),\n",
    "        file_extensions=[\".pdf\", \".PDF\"]\n",
    "    )\n",
    "    print(f\"\\n Waiting for automatic parsing to complete...\")\n",
    "    print(\"   (The Lambda function will automatically convert PDFs to markdown)\")\n",
    "else:\n",
    "    print(f\" Folder not found: {local_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitor-header",
   "metadata": {},
   "source": [
    "### Monitoring Lambda Processing\n",
    "\n",
    "Monitor processing progress in real-time via CloudWatch logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = monitor_lambda_processing(\n",
    "    logs_client=logs,\n",
    "    s3_client=s3_client,\n",
    "    bucket_name=os.getenv(\"S3_BUCKET\")\n",
    ")\n",
    "# To stop monitoring, press Esc followed by double-clicking 'i'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8-header",
   "metadata": {},
   "source": [
    "<a id=\"step8\"></a>\n",
    "\n",
    "## Step 8: Connect to the Bedrock Knowledge Base\n",
    "\n",
    "Documents are parsed and stored in S3. The next step is making them **searchable** by ingesting into the Bedrock Knowledge Base.\n",
    "\n",
    "The knowledge base was pre-configured to:\n",
    "- Point to S3 `output/medical_chunks/` folder as the data source\n",
    "- Use **Amazon Titan** for vector embeddings\n",
    "- Store vectors in **OpenSearch Serverless** for fast similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kb-list-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all your knowledge bases\n",
    "bedrock_agent = session.client(\"bedrock-agent\")\n",
    "\n",
    "print(\"All Knowledge Bases in your account:\")\n",
    "kb_response = bedrock_agent.list_knowledge_bases()\n",
    "\n",
    "for kb in kb_response.get(\"knowledgeBaseSummaries\", []):\n",
    "    print(f\"\\nKnowledge Base: {kb['name']}\")\n",
    "    print(f\"   ID: {kb['knowledgeBaseId']}\")\n",
    "    print(f\"   Status: {kb['status']}\")\n",
    "    print(f\"   Updated: {kb['updatedAt']}\")\n",
    "\n",
    "    # Get data sources for this knowledge base\n",
    "    ds_response = bedrock_agent.list_data_sources(\n",
    "        knowledgeBaseId=kb['knowledgeBaseId']\n",
    "    )\n",
    "\n",
    "    for ds in ds_response.get(\"dataSourceSummaries\", []):\n",
    "        print(f\"   Data Source: {ds['name']}\")\n",
    "        print(f\"      ID: {ds['dataSourceId']}\")\n",
    "        print(f\"      Status: {ds['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kb-ids-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDROCK_KB_ID = <your_bedrock_kb_id>\n",
    "DATA_SOURCE_ID = <your_data_source_id>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step9-header",
   "metadata": {},
   "source": [
    "<a id=\"step9\"></a>\n",
    "\n",
    "\n",
    "## Step 9: Ingest Documents into the Knowledge Base\n",
    "\n",
    "**Ingestion** syncs parsed documents from S3 into the knowledge base:\n",
    "\n",
    "1. Knowledge base reads new/modified JSON files from S3\n",
    "2. Creates vector embeddings for each chunk\n",
    "3. Stores vectors in the database for fast similarity search\n",
    "\n",
    "Once complete, you can query with natural language and retrieve relevant document sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ingest-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent.start_ingestion_job(\n",
    "    knowledgeBaseId=BEDROCK_KB_ID,\n",
    "    dataSourceId=DATA_SOURCE_ID\n",
    ")\n",
    "\n",
    "job_id = response.get(\"ingestionJob\", {}).get(\"ingestionJobId\")\n",
    "print(\"‚úÖ Knowledge base sync initiated.\")\n",
    "print(f\"   Job ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step10-header",
   "metadata": {},
   "source": [
    "<a id=\"step10\"></a>\n",
    "\n",
    "\n",
    "## Step 10: Create the Search Tool with Visual Grounding\n",
    "\n",
    "Create a **search tool** for the agent that adds **visual grounding** - linking extracted information back to exact locations in source documents.\n",
    "\n",
    "The tool flow:\n",
    "1. Query Bedrock knowledge base using **hybrid search** (keyword + semantic)\n",
    "2. For chunk JSON files, parse metadata (chunk_id, page, bbox, type)\n",
    "3. **Generate cropped chunk images** from source PDFs\n",
    "4. Upload images to S3 and return **presigned URLs**\n",
    "5. Format response with source, page, chunk type, and image URL\n",
    "\n",
    "<div align=\"left\">\n",
    "    <img src=\"images/tool.png\" width=\"900\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import strands\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore.memory.integrations.strands.config import AgentCoreMemoryConfig\n",
    "from bedrock_agentcore.memory.integrations.strands.session_manager import AgentCoreMemorySessionManager\n",
    "from visual_grounding_helper import (\n",
    "    extract_chunk_id_from_markdown,\n",
    "    extract_chunk_image  # Using extract_chunk_image for cropped images\n",
    ")\n",
    "\n",
    "@strands.tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"Search the Bedrock knowledge base for relevant medical documents with visual grounding.\"\"\"\n",
    "    try:\n",
    "        # Ensure we have the required environment variables\n",
    "        kb_id = os.getenv(\"BEDROCK_KB_ID\")  \n",
    "        bucket = os.getenv(\"S3_BUCKET\")\n",
    "        if not kb_id:\n",
    "            return \"Error: Knowledge base ID not configured. Please set BEDROCK_KB_ID environment variable.\"\n",
    "\n",
    "        # 1. Query the knowledge base using hybrid search \n",
    "        \n",
    "        # Create runtime client if needed\n",
    "        bedrock_agent_runtime = session.client(\"bedrock-agent-runtime\")\n",
    "        \n",
    "        # Query the Knowledge Base with 5 results as requested\n",
    "        response = bedrock_agent_runtime.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={\"text\": query},\n",
    "            retrievalConfiguration={\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\": 5,\n",
    "                    \"overrideSearchType\": \"HYBRID\"  # Use hybrid search for better results\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Get results and sort by score (higher score = more relevant)\n",
    "        raw_results = response.get(\"retrievalResults\", [])\n",
    "        sorted_results = sorted(raw_results, key=lambda x: x.get(\"score\", 0), reverse=True)\n",
    "        \n",
    "        results = []\n",
    "        seen_chunk_ids = set()  # Track seen chunk IDs to avoid duplicates\n",
    "\n",
    "        # 2. For each result, get the location and check if this is a chunk JSON file from medical_chunks folder\n",
    "        for result in sorted_results:\n",
    "            content = result.get(\"content\", {}).get(\"text\", \"\")\n",
    "            score = result.get(\"score\", 0)\n",
    "            location = result.get(\"location\", {})\n",
    "            \n",
    "            # Get source file from S3 location\n",
    "            s3_location = location.get(\"s3Location\", {})\n",
    "            source_uri = s3_location.get(\"uri\", \"\")\n",
    "            source_file = source_uri.split(\"/\")[-1] if source_uri else \"Unknown source\"\n",
    "            \n",
    "            # Initialize variables\n",
    "            chunk_id = None\n",
    "            visual_info = None\n",
    "            cropped_image_url = None\n",
    "            chunk_type = \"text\"\n",
    "            page = None\n",
    "            bbox = None\n",
    "            source_document = None\n",
    "            \n",
    "            # Check if this is a chunk JSON file from medical_chunks folder\n",
    "            if source_file.endswith('.json') and 'chunks' in source_uri:\n",
    "                try:\n",
    "                    # 3. Get chunk data & extract the chunk metadata \n",
    "                    # This is a chunk file - parse it directly to get all metadata\n",
    "                    chunk_key = source_uri.replace(f\"s3://{bucket}/\", \"\")\n",
    "                    chunk_response = s3_client.get_object(Bucket=bucket, Key=chunk_key)\n",
    "                    chunk_data = json.loads(chunk_response['Body'].read().decode('utf-8'))\n",
    "                    \n",
    "                    # Extract all metadata from chunk JSON\n",
    "                    chunk_id = chunk_data.get('chunk_id', '')\n",
    "                    chunk_type = chunk_data.get('chunk_type', 'text')\n",
    "                    page = chunk_data.get('page', 0)\n",
    "                    bbox = chunk_data.get('bbox', [0, 0, 1, 1])\n",
    "                    source_document = chunk_data.get('source_document', '')\n",
    "                    \n",
    "                    # The text might be in the chunk data or in the content\n",
    "                    text = chunk_data.get('text', content)\n",
    "                    \n",
    "                    # Skip if we've already seen this chunk ID\n",
    "                    if chunk_id and chunk_id in seen_chunk_ids:\n",
    "                        continue\n",
    "                    seen_chunk_ids.add(chunk_id)\n",
    "                    \n",
    "                    # 4. Generate cropped chunk image\n",
    "                    if chunk_id and source_document:\n",
    "                        source_pdf_key = f\"input/medical/{source_document}.pdf\"\n",
    "                        try:\n",
    "                            s3_client.head_object(Bucket=bucket, Key=source_pdf_key)\n",
    "                            cropped_image_url = extract_chunk_image(\n",
    "                                s3_client=s3_client,\n",
    "                                bucket=bucket,\n",
    "                                source_pdf_key=source_pdf_key,\n",
    "                                bbox=bbox,\n",
    "                                page_num=page,\n",
    "                                chunk_id=chunk_id,\n",
    "                                source_document=source_document,\n",
    "                                highlight=True,\n",
    "                                padding=10\n",
    "                            )\n",
    "                        except:\n",
    "                            pass  # PDF not found\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    # Fallback if can't parse chunk file\n",
    "                    pass\n",
    "            else:\n",
    "                # Not a chunk file, try to extract chunk ID from markdown\n",
    "                chunk_id = extract_chunk_id_from_markdown(content)\n",
    "                \n",
    "                # Skip if we've already seen this chunk ID\n",
    "                if chunk_id and chunk_id in seen_chunk_ids:\n",
    "                    continue\n",
    "                if chunk_id:\n",
    "                    seen_chunk_ids.add(chunk_id)\n",
    "            \n",
    "            # 5. Format result with all available information\n",
    "            if cropped_image_url and chunk_id and page is not None:\n",
    "                # Complete visual grounding available\n",
    "                result_text = f\"\"\"\n",
    "                **Source:** {source_document or source_file} (Relevance: {score:.2f})\n",
    "                üìÑ **Chunk ID:** {chunk_id}\n",
    "                üìç **Page:** {page}\n",
    "                üè∑Ô∏è **Chunk Type:** {chunk_type}\n",
    "                üîç **Cropped Chunk Image:** {cropped_image_url}\n",
    "                \n",
    "                **Content:**\n",
    "                {content}\"\"\"\n",
    "                results.append(result_text)\n",
    "            elif chunk_id and page is not None:\n",
    "                # Partial visual info (no image but has metadata)\n",
    "                result_text = f\"\"\"\n",
    "                **Source:** {source_document or source_file} (Relevance: {score:.2f})\n",
    "                üìÑ **Chunk ID:** {chunk_id}\n",
    "                üìç **Page:** {page}\n",
    "                üè∑Ô∏è **Chunk Type:** {chunk_type}\n",
    "                üì¶ **Bbox:** {bbox if bbox else 'Not available'}\n",
    "                \n",
    "                **Content:**\n",
    "                {content}\"\"\"\n",
    "                results.append(result_text)\n",
    "            else:\n",
    "                # No visual grounding available - use content hash as unique ID\n",
    "                content_hash = hash(content[:200])  # Hash first 200 chars for uniqueness\n",
    "                if content_hash in seen_chunk_ids:\n",
    "                    continue\n",
    "                seen_chunk_ids.add(content_hash)\n",
    "                \n",
    "                clean_source = source_file.replace('_grounding.json', '').replace('.json', '').replace('.md', '')\n",
    "                result_text = f\"\"\"**Source:** {clean_source} (Relevance: {score:.2f})\n",
    "                                **Content:**{content}\"\"\"\n",
    "                results.append(result_text)\n",
    "        \n",
    "        if results:\n",
    "            # Return only top 5 most relevant results with visual references\n",
    "            return \"\\n\\n---\\n\\n\".join(results[:5])\n",
    "        else:\n",
    "            return f\"No documents found for query: '{query}'. The knowledge base may be empty or still processing.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"ResourceNotFoundException\" in error_msg:\n",
    "            return f\"Error: Knowledge base {kb_id} not found. Please verify the BEDROCK_KB_ID is correct.\"\n",
    "        elif \"ValidationException\" in error_msg:\n",
    "            return f\"Error: Invalid query or configuration. Details: {error_msg}\"\n",
    "        else:\n",
    "            return f\"Error searching knowledge base: {error_msg}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-header",
   "metadata": {},
   "source": [
    "### Testing the Search Function\n",
    "\n",
    "Verify the search tool works before creating the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the search function before creating agent\n",
    "print(\"Testing knowledge base search function...\")\n",
    "test_result = search_knowledge_base(\"common cold symptoms\")\n",
    "print(f\"Test result: {test_result[:200]}...\")\n",
    "\n",
    "if \"Error\" in test_result:\n",
    "    print(\"\\n Knowledge base search is not working. Checking configuration...\")\n",
    "    print(f\"Current KB ID: {os.getenv('BEDROCK_KB_ID')}\")\n",
    "    print(f\"Current Region: {os.getenv('AWS_REGION')}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Knowledge base search is working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "print-test-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step11-header",
   "metadata": {},
   "source": [
    "<a id=\"step11\"></a>\n",
    "\n",
    "\n",
    "## Step 11: Create Memory for the Agent\n",
    "\n",
    "AWS Bedrock AgentCore provides **persistent memory** so your agent remembers conversations and learns preferences over time.\n",
    "\n",
    "### Memory Strategies\n",
    "\n",
    "| Strategy | What It Does | Example |\n",
    "|----------|--------------|--------|\n",
    "| **Summary** | Summarizes past sessions | \"Last time we discussed cold treatments\" |\n",
    "| **User Preference** | Learns user preferences | \"User prefers short answers\" |\n",
    "| **Semantic** | Extracts and stores facts | \"User mentioned they have allergies\" |\n",
    "\n",
    "Memory persists across sessions, enabling personalized responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory client\n",
    "memory_client = MemoryClient(region_name=os.getenv(\"AWS_REGION\", \"us-west-2\"))\n",
    "\n",
    "# Try to list existing memories first\n",
    "try:\n",
    "    existing_memories = memory_client.gmcp_client.list_memories()\n",
    "    memory_list = existing_memories.get('memories', [])\n",
    "    \n",
    "    # Get all MedicalAgentMemory instances and use the most recent\n",
    "    medical_memories = [m for m in memory_list if 'MedicalAgentMemory' in m.get('id', '')]\n",
    "    \n",
    "    if medical_memories:\n",
    "        # Sort by creation date and take the most recent\n",
    "        medical_memories.sort(key=lambda x: x.get('createdAt', ''), reverse=True)\n",
    "        existing_medical_memory = medical_memories[0]\n",
    "        MEMORY_ID = existing_medical_memory.get('id')\n",
    "        print(f\"Found {len(medical_memories)} existing MedicalAgentMemory instance(s)\")\n",
    "        print(f\" Using most recent memory: {MEMORY_ID}\")\n",
    "        print(f\"   Created: {existing_medical_memory.get('createdAt', 'N/A')}\")\n",
    "        print(f\"   Status: {existing_medical_memory.get('status', 'N/A')}\")\n",
    "    else:\n",
    "        # Only create if none exist\n",
    "        raise Exception(\"No existing MedicalAgentMemory found, will create new one\")\n",
    "        \n",
    "except Exception as e:\n",
    "    # Create new memory only if none exists\n",
    "    print(f\" Creating new memory... (Reason: {e})\")\n",
    "    try:\n",
    "        # Add timestamp to make name unique\n",
    "        comprehensive_memory = memory_client.create_memory_and_wait(\n",
    "            name=f\"MedicalAgentMemory_{datetime.now().strftime('%Y%m%d_%H%M%S')}\", \n",
    "            description=\"Memory for medical document analysis with user preferences\",\n",
    "            strategies=[\n",
    "                {\n",
    "                    \"summaryMemoryStrategy\": {\n",
    "                        \"name\": \"SessionSummarizer\",\n",
    "                        \"namespaces\": [\"/summaries/{actorId}/{sessionId}\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"userPreferenceMemoryStrategy\": {\n",
    "                        \"name\": \"PreferenceLearner\",\n",
    "                        \"namespaces\": [\"/preferences/{actorId}\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"semanticMemoryStrategy\": {\n",
    "                        \"name\": \"FactExtractor\",\n",
    "                        \"namespaces\": [\"/facts/{actorId}\"]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        MEMORY_ID = comprehensive_memory.get('id')\n",
    "        print(f\" New memory created: {MEMORY_ID}\")\n",
    "    except Exception as create_error:\n",
    "        print(f\" Could not create memory: {create_error}\")\n",
    "        print(\"Continuing without memory functionality...\")\n",
    "        MEMORY_ID = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "session-header",
   "metadata": {},
   "source": [
    "### Configuring the Memory Session\n",
    "\n",
    "The session manager requires two identifiers:\n",
    "- **Actor ID**: Who is using the agent (enables personalization)\n",
    "- **Session ID**: Unique identifier for this conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "session-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up memory configuration if memory exists\n",
    "if MEMORY_ID:\n",
    "    ACTOR_ID = f\"medical_user_{datetime.now().strftime('%H%M%S')}\"\n",
    "    SESSION_ID = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "    print(f\"   Actor: {ACTOR_ID}\")\n",
    "    print(f\"   Session: {SESSION_ID}\")\n",
    "\n",
    "    # Configure memory\n",
    "    memory_config = AgentCoreMemoryConfig(\n",
    "        memory_id=MEMORY_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        actor_id=ACTOR_ID\n",
    "    )\n",
    "\n",
    "    # Create session manager\n",
    "    session_manager = AgentCoreMemorySessionManager(\n",
    "        agentcore_memory_config=memory_config,\n",
    "        region_name=os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
    "    )\n",
    "else:\n",
    "    session_manager = None\n",
    "    print(\"Agent will run without memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712d71d-9de5-4226-bff6-6129ef740c48",
   "metadata": {},
   "source": [
    "<a id=\"step12\"></a>\n",
    "\n",
    "\n",
    "## Step 12: Create the Strands Agent\n",
    "\n",
    "Bring everything together into a **Strands Agent** configured with:\n",
    "- **Model**: Claude via Bedrock as the underlying LLM\n",
    "- **System prompt**: Instructions defining agent behavior\n",
    "- **Session manager**: Memory for preferences and history\n",
    "- **Tools**: The `search_knowledge_base` function with visual grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "\n",
    "# Create the agent with memory and tools\n",
    "medical_agent = Agent(\n",
    "    model=os.getenv(\"BEDROCK_MODEL_ID\"),\n",
    "    name=\"Medical Document Analyzer with Memory\",\n",
    "    description=\"Expert agent for medical documents with conversation memory\",\n",
    "    system_prompt=\"\"\"\n",
    "        You are a medical document analysis assistant with memory capabilities and visual grounding support.\n",
    "        You remember our conversations, user preferences, and important facts.\n",
    "        \n",
    "        Your capabilities:\n",
    "        - Search and analyze medical documents from the knowledge base\n",
    "        - Provide visual grounding information showing exact locations in documents\n",
    "        - Display page numbers and bounding box coordinates when available\n",
    "        - Reference annotated images that highlight specific document regions\n",
    "        - Remember user preferences and conversation history\n",
    "        - Provide personalized, contextual responses\n",
    "        - Learn from interactions to improve future responses\n",
    "        \n",
    "        IMPORTANT: When you receive search results that include visual grounding information, you MUST include:\n",
    "        - Page numbers where information was found\n",
    "        - Location coordinates showing exact position on the page\n",
    "        - Annotated image URLs that show highlighted text regions\n",
    "        \n",
    "        When search results contain these visual markers, preserve them in your response. Do not summarize away the visual grounding details.\n",
    "        \n",
    "        Visual grounding format to preserve:\n",
    "        - **Page:** [number] - shows which page contains the information\n",
    "        - **Location:** [coordinates] - shows exact position on the page\n",
    "        - **Annotated Image:** [URL] - provides visual highlight of the referenced text\n",
    "        \n",
    "        You have access to medical documents about common cold, treatments, and symptoms.\n",
    "        Always provide evidence-based insights from the documents with visual references when available.\n",
    "        When visual grounding is provided in search results, include it in your response to help users see exactly where information comes from.\n",
    "        \"\"\",\n",
    "    session_manager=session_manager,\n",
    "    tools=[search_knowledge_base]\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Medical agent ready with memory and visual grounding!\")\n",
    "print(f\"   Model: {os.getenv('BEDROCK_MODEL_ID')}\")\n",
    "print(f\"   Tools: {medical_agent.tool_names}\")\n",
    "print(\"\\nThe agent will now:\")\n",
    "print(\"   - Remember your preferences and conversation history\")\n",
    "print(\"   - Show exact locations in documents when available\")\n",
    "print(\"   - Provide visual grounding with page numbers and coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step13-header",
   "metadata": {},
   "source": [
    "<a id=\"step13\"></a>\n",
    "\n",
    "\n",
    "## Step 13: Interactive Chat\n",
    "\n",
    "Your medical document agent is ready! Start an interactive chat session to:\n",
    "- Ask questions about medical documents\n",
    "- See visual grounding with page numbers and image URLs\n",
    "- Tell the agent your preferences (e.g., \"I prefer short answers\")\n",
    "- Watch the agent remember preferences in future sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be498acb-9c08-415a-a28c-1eb4abf10acc",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> üö®\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Medical Agent - Interactive Chat with Visual Grounding\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAsk questions about medicine.\")\n",
    "print(\"Type 'exit', 'quit', or 'bye' to end the conversation.\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "conversation_num = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "\n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye', 'q']:\n",
    "            print(\"\\n Ending conversation. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        conversation_num += 1\n",
    "\n",
    "        # Display the question prominently\n",
    "        print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "        print(f\"Question #{conversation_num} [{datetime.now().strftime('%H:%M:%S')}]\")\n",
    "        print(f\"   \\\"{user_input}\\\"\")\n",
    "        print(\"‚îÄ\" * 70)\n",
    "\n",
    "        print(\"\\nAgent Response:\")\n",
    "        print(\"   Processing...\\n\")\n",
    "\n",
    "        # Get and display the response\n",
    "        result = medical_agent(user_input)\n",
    "        print(result)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n Conversation interrupted. Goodbye!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error: {e}\")\n",
    "        print(\"Please try again or type 'exit' to quit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-cell",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Here's what you built in Lab 6:\n",
    "\n",
    "| Component | Service | Function |\n",
    "|-----------|------------|--------|\n",
    "| **Storage** | Amazon S3 | Store raw PDFs and parsed outputs |\n",
    "| **Trigger** | AWS Lambda | Serverless document parsing with ADE |\n",
    "| **Vector DB** | Bedrock Knowledge Base | Semantic search over documents |\n",
    "| **Agent** | Strands Agents | Conversational interface |\n",
    "| **Memory** | AgentCore Memory | Remember preferences and history |\n",
    "\n",
    "You can extend this pipeline to handle other document types, add more tools, or integrate with other AWS services as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

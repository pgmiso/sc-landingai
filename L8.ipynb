{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Lab 4: Document Understanding with Agentic Document Extraction\n",
    "\n",
    "In this lab, you will use LandingAI's Agentic Document Extraction (ADE) framework to parse documents and extract key-value pairs using a single API. Note that Lab 4 has two parts. Here in the first part, we cover Exercise 1: Extract Key-Value Pairs from a Utility Bill and Exercise 2: ADE on Difficult Documents. In the second part, we cover Exercise 3: Automated Pipeline for Loan Applications.   \n",
    "\n",
    "**Learning Objectives:**\n",
    "- Use the Parse API to convert documents into structured markdown with visual grounding\n",
    "- Define JSON schemas to extract specific fields from documents\n",
    "- Use the Extract API to pull key-value pairs with source location references\n",
    "\n",
    "## Background\n",
    "\n",
    "ADE is built on three approaches:\n",
    "- Vision-First: Documents are visual objects where meaning is encoded in layout, structure, and spatial relationships\n",
    "- Data-Centric: Models are trained on large, diverse, and curated datasets\n",
    "- Agentic: The system plans, decides, acts, and verifies until responses meet quality thresholds\n",
    "\n",
    "The foundation is the **Document Pre-trained Transformer (DPT)** family of models that combine text parsing, layout detection, reading order, and multimodal reasoning capabilities.\n",
    "\n",
    "## Outline\n",
    "\n",
    "- [1. Setup and Authentication](#1)\n",
    "- [2. Helper Functions](#2)\n",
    "- [3. Exercise 1: Extract Key-Value Pairs from a Utility Bill](#3)\n",
    "  - [3.1 Preview the Document](#3-1)\n",
    "  - [3.2 Parse the Document](#3-2)\n",
    "  - [3.3 Explore the Output from Parse](#3-3)\n",
    "  - [3.4 Extract Key-Value Pairs](#3-4)\n",
    "  - [3.5 Explore the Output from Extract](#3-5)\n",
    "- [4. Exercise 2: ADE on Difficult Documents](#4)\n",
    "  - [4.1 Charts and Flowcharts](#4-1)\n",
    "  - [4.2 Tables with Missing Gridlines](#4-2)\n",
    "  - [4.3 Handwritten Forms](#4-3)\n",
    "  - [4.4 Handwritten Calculus](#4-4)\n",
    "  - [4.5 Illustrations and Infographics](#4-5)\n",
    "  - [4.6 Stamps and Signatures](#4-6)\n",
    "- [5. Summary](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "## 1. Setup and Authentication\n",
    "\n",
    "Import the required libraries. Key imports from LandingAI:\n",
    "- `LandingAIADE`: Client for making API calls\n",
    "- `ParseResponse`: Type for document parsing results\n",
    "- `ExtractResponse`: Type for field extraction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7bfa7-c958-4b5c-882b-dcdb10ee7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pymupdf\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, IFrame, Markdown, HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "from PIL import Image as PILImage, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b5cf1-ec67-4155-9326-47551cc9e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports specific to Agentic Document Extraction\n",
    "\n",
    "from landingai_ade import LandingAIADE\n",
    "from landingai_ade.types import ParseResponse, ExtractResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e2df8-d3ac-49f0-9dba-04eb12354157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "_ = load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "client-note",
   "metadata": {},
   "source": [
    "Initialize the ADE client. The API key is loaded automatically from the environment variable `VISION_AGENT_API_KEY`.\n",
    "\n",
    "To use ADE outside this course, you can generate a free API key at [va.landing.ai](https://va.landing.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d456bf-a754-4eae-9962-6be5c834607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = LandingAIADE()\n",
    "print(\"Authenticated client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "## 2. Helper Functions\n",
    "\n",
    "Import visualization functions from `helper.py` to display documents and draw bounding boxes around detected chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f6b71-1487-434e-b93b-789194a80289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import print_document, draw_bounding_boxes, draw_bounding_boxes_2\n",
    "from helper import create_cropped_chunk_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Exercise 1: Extract Key-Value Pairs from a Utility Bill\n",
    "\n",
    "Parse a utility bill and extract specific fields like current charges, gas usage, and electric usage. The workflow:\n",
    "1. Preview the document\n",
    "2. Parse with DPT-2 to get structured markdown and chunks\n",
    "3. Extract key-value pairs using a JSON schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4978ef-a6cd-47c4-a783-af28bdc8150e",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> LandingAI continues to innovate with DPT-2. Considering updates to the model, your results might differ slightly from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1",
   "metadata": {},
   "source": [
    "<a id=\"3-1\"></a>\n",
    "\n",
    "### 3.1 Preview the Document\n",
    "\n",
    "A combined gas and electric bill from a San Diego utility with monthly billing period, separate charges, and usage history charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb6651-45dc-4645-9d6f-24d1be46326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"utility_example/utility_bill.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-2",
   "metadata": {},
   "source": [
    "<a id=\"3-2\"></a>\n",
    "\n",
    "### 3.2 Parse the Document\n",
    "\n",
    "The Parse API converts the document into structured markdown with:\n",
    "- Chunks: Semantic regions (text, tables, figures, logos, marginalia)\n",
    "- Bounding boxes: Coordinates for each chunk\n",
    "- Markdown: Text representation with embedded chunk IDs\n",
    "\n",
    "Using `dpt-2-latest` provides the most current version of the DPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6fe33-dcf3-472a-aee4-b48551403479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path to the document\n",
    "document_path = Path(\"utility_example/utility_bill.pdf\")\n",
    "\n",
    "print(\"âš¡ Calling API to parse document...\")\n",
    "\n",
    "# Parse the document using the Parse() API\n",
    "parse_result: ParseResponse = client.parse(\n",
    "    document=document_path,\n",
    "    model=\"dpt-2-latest\"\n",
    ")\n",
    "\n",
    "print(f\"Parsing completed.\")\n",
    "print(f\"job_id: {parse_result.metadata.job_id}\")\n",
    "print(f\"Filename: {parse_result.metadata.filename}\")\n",
    "print(f\"Total time (ms): {parse_result.metadata.duration_ms}\")\n",
    "print(f\"Total pages: {len(parse_result.splits)}\")\n",
    "print(f\"Total markdown characters: {len(parse_result.markdown)}\")\n",
    "print(f\"Total chunks: {len(parse_result.chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-3",
   "metadata": {},
   "source": [
    "<a id=\"3-3\"></a>\n",
    "\n",
    "### 3.3 Explore the Output from Parse\n",
    "\n",
    "The parse result contains the document structure. Visualize the detected chunks with bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef571afd-8806-437d-ac40-f5676c92b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and view an annotated version\n",
    "draw_bounding_boxes(parse_result, document_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chunk-inspect",
   "metadata": {},
   "source": [
    "Each chunk has a unique ID, type, page number, and bounding box coordinates. Chunk types include: `logo`, `text`, `table`, `figure`, and `marginalia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6245d77-546f-4902-a391-138e065a71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first 5 chunks\n",
    "parse_result.chunks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78692b99-0d83-486f-868c-cf36c4138319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The first chunk has an id: {parse_result.chunks[0].id}\")\n",
    "print(f\"The first chunk is type: {parse_result.chunks[0].type}\")\n",
    "print(f\"The first chunk is on page: {parse_result.chunks[0].grounding.page}\")\n",
    "print(f\"The first chunk is at box coordinates: {parse_result.chunks[0].grounding.box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1b4a4-6d95-4207-b193-b1cb4dc5334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many chunks of each type?\n",
    "counts = {}\n",
    "\n",
    "for chunk in parse_result.model_dump()[\"chunks\"]:\n",
    "    t = chunk[\"type\"]\n",
    "    counts[t] = counts.get(t, 0) + 1\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown-note",
   "metadata": {},
   "source": [
    "The top-level markdown contains the full document content with embedded chunk IDs. These IDs enable visual grounding namely tracing extracted values to their source location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d981412-6587-4c66-9cdc-f159d876bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP-LEVEL MARKDOWN CONTENTS\")\n",
    "print(f\"{parse_result.markdown[0:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-markdown",
   "metadata": {},
   "source": [
    "Tables are rendered as HTML with unique IDs for each cell. This enables extraction to reference specific table cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8329a5-6536-470d-8750-004a70393dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk-level markdown rendered\n",
    "display(HTML(parse_result.chunks[9].markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df81af9-dc8c-4985-8304-9c881382a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \")\n",
    "print(\"CHUNK-LEVEL MARKDOWN CONTENTS\")\n",
    "print(f\"{parse_result.chunks[9].markdown}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-4",
   "metadata": {},
   "source": [
    "<a id=\"3-4\"></a>\n",
    "\n",
    "### 3.4 Extract Key-Value Pairs from the Document\n",
    "\n",
    "Define a JSON schema specifying the fields to extract. The schema supports:\n",
    "- Nested objects: (e.g., `account_summary` with sub-fields)\n",
    "- Multiple types: `number`, `string`, `boolean`\n",
    "- Rich descriptions: Guide the extraction model\n",
    "\n",
    "More descriptive field definitions improve extraction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43776da-e4c5-4ece-b6b3-08b2b8bc8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {\n",
    "    \"type\": \"object\",\n",
    "    \"title\": \"Utility Bill Field Extraction Schema\",\n",
    "    \"properties\": {\n",
    "    \"account_summary\": {\n",
    "      \"type\": \"object\",\n",
    "      \"title\": \"Account Summary\",\n",
    "      \"properties\": {\n",
    "        \"current_charges\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"The charges incurred during the current billing \"\n",
    "            \"period.\"\n",
    "        },\n",
    "        \"total_amount_due\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"The total amount currently due.\"\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"gas_summary\": {\n",
    "      \"type\": \"object\",\n",
    "      \"title\": \"Gas Usage Summary\",\n",
    "      \"properties\": {\n",
    "        \"total_therms_used\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"Total therms of gas used in the billing period.\"\n",
    "        },\n",
    "        \"gas_current_charges\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"The gas charges incurred during the current \"\n",
    "            \"billing period.\"\n",
    "        },\n",
    "        \"gas_usage_chart\": {\n",
    "          \"type\": \"boolean\",\n",
    "          \"description\": \"Does the document contain a chart of historical \"\n",
    "            \"gas usage?\"\n",
    "        },\n",
    "        \"gas_max_month\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Which month has the highest historical gas usage? \"\n",
    "            \"Return month name only.\"\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"electric_summary\": {\n",
    "      \"type\": \"object\",\n",
    "      \"title\": \"Electric Usage Summary\",\n",
    "      \"properties\": {\n",
    "        \"total_kwh_used\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"Total kilowatt hours of electricity used in the \"\n",
    "            \"billing period.\"\n",
    "        },\n",
    "        \"electric_current_charges\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"The gas charges incurred during the current \"\n",
    "            \"billing period.\"\n",
    "        },\n",
    "        \"electric_usage_chart\": {\n",
    "          \"type\": \"boolean\",\n",
    "          \"description\": \"Does the document contain a chart of historical \"\n",
    "            \"electric usage?\"\n",
    "        },\n",
    "        \"electric_max_month\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Which month has the highest historical electric \"\n",
    "            \"usage? Return month name only.\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a JSON-formatted string\n",
    "schema_json = json.dumps(schema_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract-call",
   "metadata": {},
   "source": [
    "Call the Extract API with the schema and markdown from the parse step. The Extract API uses the structured markdown from the Parse API to find the requested fields in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d66fe-c96e-4fbd-9607-9acee80049db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš¡ Calling API to extract from the document...\")\n",
    "\n",
    "# Using the Extract() API to extract structured data using the schema\n",
    "extraction_result: ExtractResponse = client.extract(\n",
    "            schema=schema_json,\n",
    "            markdown=parse_result.markdown, # Notice that the input used is the top-level markdown from the parse step\n",
    "            model=\"extract-latest\"\n",
    ")\n",
    "\n",
    "print(f\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-5",
   "metadata": {},
   "source": [
    "<a id=\"3-5\"></a>\n",
    "\n",
    "### 3.5 Explore the Output from Extract\n",
    "\n",
    "The extraction result contains:\n",
    "- extraction: The extracted values matching your schema\n",
    "- extraction_metadata: References to source chunk/cell IDs for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a582be-334b-436f-9f86-f9d27525919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all extracted values\n",
    "extraction_result.extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metadata-note",
   "metadata": {},
   "source": [
    "The metadata provides visual grounding. Short IDs like `0-a` refer to table cells, while longer UUIDs refer to figure or text chunks. This enables verification UIs that highlight the exact source of each extracted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8fa148-7656-4331-ad88-fd14c0912c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all metadata for extracted values\n",
    "extraction_result.extraction_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "## 4. Exercise 2: ADE Performance on Difficult-to-Parse Documents\n",
    "\n",
    "See how ADE handles document types that are challenging for traditional OCR and VLM approaches:\n",
    "- Charts and flowcharts with complex spatial relationships\n",
    "- Tables with missing gridlines and merged cells\n",
    "- Handwritten forms with checkboxes and circles\n",
    "- Illustrations without text\n",
    "- Official stamps and signatures\n",
    "\n",
    "The same API and DPT model handles all of these without additional configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099341a-1d70-4f9d-873d-d9f1ee1b35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(parse_filename: str, model = \"dpt-2-latest\", \n",
    "                   display_option = \"HTML\") -> ParseResponse:\n",
    "    \"\"\"\n",
    "    Parse a document with ADE and display the result in the desired format.\n",
    "\n",
    "    Args:\n",
    "        parse_filename: Path to the document to parse.\n",
    "        display_option: One of:\n",
    "            - \"Raw Markdown\" : print the markdown as plain text\n",
    "            - \"HTML\"         : render the markdown as HTML in the notebook\n",
    "\n",
    "    Returns:\n",
    "        ParseResponse: The full parse response object.\n",
    "    \"\"\"\n",
    "\n",
    "    document_path = Path(parse_filename)\n",
    "    \n",
    "    print(\"âš¡ Calling API to parse document...\")\n",
    "    \n",
    "    full_parse_result: ParseResponse = client.parse(  \n",
    "        #send document to Parse API\n",
    "        document=document_path, \n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    _ = draw_bounding_boxes(full_parse_result, document_path=document_path)\n",
    "\n",
    "    print(f\"Parsing completed.\")\n",
    "    print(f\"job_id: {full_parse_result.metadata.job_id}\")\n",
    "    print(f\"Total pages: {len(full_parse_result.splits)}\")\n",
    "    print(f\"Total time (ms): {full_parse_result.metadata.duration_ms}\")\n",
    "    print(f\"Total markdown characters: {len(full_parse_result.markdown)}\")\n",
    "    print(f\"Number of chunks: {len(full_parse_result.chunks)}\")\n",
    "    print(f\" \")\n",
    "    print(\"Complete Markdown:\")\n",
    "\n",
    "    if display_option == \"Raw Markdown\":\n",
    "        print(\"Complete Markdown (raw):\")\n",
    "        print(full_parse_result.markdown)\n",
    "\n",
    "    elif display_option == \"HTML\":\n",
    "        print(\"Rendering markdown as HTML...\")\n",
    "        display(HTML(full_parse_result.markdown))\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"[Unknown display_option '{display_option}'; \"\n",
    "            \"valid options are 'Raw Markdown' or 'HTML'. \"\n",
    "            \"Defaulting to HTML.]\"\n",
    "        )\n",
    "        display(HTML(full_parse_result.markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-1",
   "metadata": {},
   "source": [
    "<a id=\"4-1\"></a>\n",
    "\n",
    "### 4.1 Charts and Flowcharts\n",
    "\n",
    "Charts encode meaning through bars, lines, and spatial relationships. Flowcharts use arrows to show connections that don't follow standard reading order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed418bfd-b952-4ca6-b996-f486a9f554b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/Investor_Presentation_pg7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23525c-9878-4f3d-9bd2-369e2741c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/Investor_Presentation_pg7.png\", \n",
    "               display_option = \"Raw Markdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flowchart-note",
   "metadata": {},
   "source": [
    "This HR flowchart has arrows pointing in multiple directions. Traditional OCR would fail because \"Select candidate\" appears *above* \"Good reference\" on the page, but logically follows it in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb69da-0487-4b5d-ab88-6d63f9c5a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/hr_process_flowchart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ef9bc-cfc9-474d-9ad8-c0bdcced15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/hr_process_flowchart.png\", \n",
    "               display_option = \"HTML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-2",
   "metadata": {},
   "source": [
    "<a id=\"4-2\"></a>\n",
    "\n",
    "### 4.2 Tables with Many Cells, Missing Gridlines, and Merged Cells\n",
    "\n",
    "Real-world tables often lack clear gridlines, have merged header cells, or contain blank cells. ADE handles these by understanding the visual structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f7ac8-2df4-4ab8-b4ef-f9f11e962dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/virology_pg2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53692f8-ac5c-4d4d-bf65-98f690925310",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/virology_pg2.pdf\", \n",
    "               display_option = \"HTML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mega-table",
   "metadata": {},
   "source": [
    "This \"mega table\" has over 1,000 cells with merged rows and columns. LLMs typically hallucinate on large tables because they can't hold all the numbers in context. The agentic approach processes tables visually, avoiding this limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab299fc-d1a9-4fde-af13-3c1ff4be19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/sales_volume.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ab309-ec15-467c-9ab8-41ca17858a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/sales_volume.png\", \n",
    "               display_option = \"HTML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-3",
   "metadata": {},
   "source": [
    "<a id=\"4-3\"></a>\n",
    "\n",
    "### 4.3 Handwritten Form with Checkboxes and Circles\n",
    "\n",
    "This patient intake form combines handwriting, checkboxes, and circled selections. ADE detects these interaction patterns and converts them to structured markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea3246-a6f5-44c6-bfe7-d323a78f9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/patient_intake.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef925c-6689-4e24-91d6-df410ed8fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/patient_intake.pdf\", \n",
    "               display_option = \"Raw Markdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-4",
   "metadata": {},
   "source": [
    "<a id=\"4-4\"></a>\n",
    "\n",
    "### 4.4 Handwritten Calculus Answer Sheet\n",
    "\n",
    "Mathematical notation like integrals, square roots, and fractions requires understanding visual symbols. ADE can parse handwritten math into structured representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448b3e9-a785-462f-b4ef-b1f8fb6cf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/calculus_BC_answer_sheet.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e07cb-47c9-4a5a-9e6a-7e5378b2de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/calculus_BC_answer_sheet.jpg\", display_option = \"HTML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-5",
   "metadata": {},
   "source": [
    "<a id=\"4-5\"></a>\n",
    "\n",
    "### 4.5 Illustrations and Infographics\n",
    "\n",
    "Some documents contain no text - only illustrations. For these, use `dpt-1-latest` which provides more detailed figure descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6cf09-5703-421f-9348-416d82921822",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/ikea-assembly.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972268f2-df1f-4cc2-a401-f022a1f1dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/ikea-assembly.pdf\", \n",
    "               model = \"dpt-1-latest\", \n",
    "               display_option = \"Raw Markdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab13ae1-06e0-4a5e-9937-1e20104740f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/ikea_infographic.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbfc7f-7ac6-48f4-84e0-52ffc5a2ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/ikea_infographic.jpg\", \n",
    "               display_option = \"Raw Markdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-6",
   "metadata": {},
   "source": [
    "<a id=\"4-6\"></a>\n",
    "\n",
    "### 4.6 Certificate of Origin with Stamps and Signatures\n",
    "\n",
    "Official documents often contain stamps with curved text and handwritten signatures. ADE detects these as `attestation` chunk types and extracts their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eb3e4-dd75-48aa-b813-9da78acb4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_document(\"difficult_examples/certificate_of_origin.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77561cb-22aa-4249-b846-c2e1e7c3b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_document(\"difficult_examples/certificate_of_origin.pdf\", \n",
    "               display_option = \"HTML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "\n",
    "## 5. Summary\n",
    "\n",
    "Here's what we learned about LandingAI's ADE framework:\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Parse API** | Converts documents to structured markdown with chunks, bounding boxes, and unique IDs |\n",
    "| **Extract API** | Pulls key-value pairs using JSON schemas with references for visual grounding |\n",
    "| **DPT Models** | Document Pre-trained Transformers (DPT-2) that understand documents visually |\n",
    "| **Chunk Types** | `logo`, `text`, `table`, `figure`, `marginalia`, `attestation` |\n",
    "| **Visual Grounding** | Each extracted value references its source chunk |\n",
    "\n",
    "In the next lab, you will build a complete document processing pipeline for loan automation using document categorization and extraction schemas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "L1L5",
   "language": "python",
   "name": "l1l5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
